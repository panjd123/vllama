# vllama Environment Variables
# Copy this file to .env and customize as needed
# Or override directly when starting: VLLAMA_OFFLINE_MODE=false docker-compose up -d

# ==================== Offline Mode ====================
# Cache model list after first scan (recommended for production)
# true: Cache model list, better performance
# false: Always scan disk, auto-discover new models
VLLAMA_OFFLINE_MODE=true

# ==================== Server Settings ====================
VLLAMA_HOST=0.0.0.0
VLLAMA_PORT=33258

# ==================== vLLM Instance Ports ====================
VLLAMA_VLLM_PORT_START=33300
VLLAMA_VLLM_PORT_END=34300

# ==================== Auto-Unload Settings ====================
# Seconds before auto-unloading inactive models
VLLAMA_UNLOAD_TIMEOUT=1800

# Unload mode: 1=light sleep, 2=deep sleep, 3=stop instance
VLLAMA_UNLOAD_MODE=2

# ==================== GPU Settings ====================
# Default GPU device ID (leave empty for auto-select)
# VLLAMA_DEFAULT_DEVICE=0

# ==================== Hugging Face ====================
# HF_HOME=/root/.cache/huggingface
# HF_TOKEN=your_token_here
